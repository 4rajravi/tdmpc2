# ----------------------------------------------------------
# Total environment interaction
# ----------------------------------------------------------
steps: 1_000_000

# ----------------------------------------------------------
# Replay buffer
# ----------------------------------------------------------
buffer_size: 100_000
batch_size: 128
seed_steps: 5_000

# ----------------------------------------------------------
# Optimization
# ----------------------------------------------------------
lr: 3e-4
grad_clip_norm: 20.0

# ----------------------------------------------------------
# Discounting & target networks
# ----------------------------------------------------------
discount: 0.99
vmin: -100.0
vmax: 100.0
tau: 0.01

# ----------------------------------------------------------
# TD-MPC2 loss weights
# ----------------------------------------------------------
reward_coef: 0.5
value_coef: 0.5
consistency_coef: 10.0
termination_coef: 1.0

# ----------------------------------------------------------
# Temporal weighting
# ----------------------------------------------------------
rho: 0.75

# ----------------------------------------------------------
# Training schedule
# ----------------------------------------------------------
update_every: 1
updates_per_step: 2
