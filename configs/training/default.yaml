# ----------------------------------------------------------
# Total environment interaction
# ----------------------------------------------------------
steps: 500_000

# ----------------------------------------------------------
# Replay buffer
# ----------------------------------------------------------
buffer_size: 100_000
batch_size: 128
seed_steps: 12_000

# ----------------------------------------------------------
# Optimization
# ----------------------------------------------------------
lr: 2e-4
grad_clip_norm: 20.0

# ----------------------------------------------------------
# Discounting & target networks
# ----------------------------------------------------------
discount: 0.99
vmin: -10.0
vmax: 10.0
tau: 0.01

# ----------------------------------------------------------
# TD-MPC2 loss weights
# ----------------------------------------------------------
reward_coef: 1.0
value_coef: 0.4
consistency_coef: 4.0
termination_coef: 0.0

# ----------------------------------------------------------
# Temporal weighting
# ----------------------------------------------------------
rho: 0.5

# ----------------------------------------------------------
# Training schedule
# ----------------------------------------------------------
update_every: 1
updates_per_step: 1






# steps: 1_000_000
# buffer_size: 100_000
# batch_size: 128
# seed_steps: 5_000
# lr: 3e-4
# grad_clip_norm: 20.0
# discount: 0.99
# vmin: -1000.0
# vmax: 1000.0
# tau: 0.01
# value_coef: 0.5
# consistency_coef: 4.0
# termination_coef: 0.0
# rho: 0.5
# updates_per_step: 1
